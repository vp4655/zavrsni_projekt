{
    "contents" : "#install.packages('maptools');\n#install.packages('rgdal');\n#install.packages('PBSmapping')\nlibrary(maptools)\nlibrary(sp)\nlibrary(rgdal)\nlibrary(PBSmapping)\n\n# Učitavnja SHAPEFILE-a Bioclim --------------------------------------------------\n\ndata.shapes = readOGR(\"./bioclim/33.shp\", \"33\")\n\np4s.latlon = CRS(proj4string(data.shapes))\n\ndata.forPlot = spTransform(data.shapes, p4s.latlon);\n\n# Učitavnja SHAPEFILE-a Dem --------------------------------------------------\n\ndata.shapesDem = readOGR(\"./dem/30.shp\", \"30\")\n\n# Učitavanje CSV-a -------------------------------------------------------\n\nnalOp = read.csv(\"./nalOpMin.csv\", header = TRUE, sep = \";\", quote = \"\\\"\", stringsAsFactors = F)\nhead(nalOp, 1)\n\nnalLit = read.csv(\"./nalLitMin.csv\", header = TRUE, sep = \";\", quote = \"\\\"\", stringsAsFactors = F)\nhead(nalLit, 1)\n\n# Izdvanjanje koordinatnih matrica NalazisteOp ---------------------------------------\n\nonlyXY = nalOp[c('HTRS96_X', 'HTRS96_Y')]\n\nmatKoor1 = matrix(transform(onlyXY, HTRS96_X = as.numeric(HTRS96_X))[,1], nrow = nrow(onlyXY), ncol = 1)\nmatKoor2 = matrix(transform(onlyXY, HTRS96_Y = as.numeric(HTRS96_Y))[,2], nrow = nrow(onlyXY), ncol = 1)\n\nmatrica = cbind(matKoor1, matKoor2)\nmate = matrica[10270:17534,]\nmate2 = matrica[6870:10260,]\nmate3 = matrica[1:6860,]\n\nkoordinate1 = SpatialPoints(mate, proj4string = p4s.latlon)\nkoordinate2 = SpatialPoints(mate2, proj4string = p4s.latlon)\nkoordiante3 = SpatialPoints(mate3, proj4string = p4s.latlon)\n\nkoordinate = rbind(koordinate1, koordinate2, koordiante3)\n\n# Izdvanjanje koordinatnih matrica NalazisteLit ---------------------------------------\n\nonlyXYLit = nalLit[c('HTRS96_X', 'HTRS96_Y')]\nonlyXY100Lit = head(onlyXYLit, 100) # 100 podataka samo za test\nstr(onlyXY100Lit)\n\nmatKoor1Lit = matrix(transform(onlyXYLit, HTRS96_X = as.double(HTRS96_X))[,1], nrow = nrow(onlyXYLit), ncol = 1)\nmatKoor2Lit = matrix(transform(onlyXYLit, HTRS96_Y = as.double(HTRS96_Y))[,2], nrow = nrow(onlyXYLit), ncol = 1)\n\nmatricaLit = cbind(matKoor1Lit, matKoor2Lit)\n\nkoordinateLit = SpatialPoints(matricaLit, proj4string = p4s.latlon)\nkoordinateLit\n\n# Dohvaćanje presječnih podataka za Op i Lit -----------------------------------------\n\ndata.matrixOpBioclim = over(koordinate, data.shapes);\n\ndata.matrixOpDem = over(koordinate, data.shapesDem);\n\ndata.matrixLitBioclim = over(koordinateLit, data.shapes)\n\ndata.matrixLitDem = over(koordinateLit, data.shapesDem)\n\n# Stvaranje spojene matrice za Op ------------------------------------------------------------\n\ndata.opFinal = nalOp[c('OznKoord', 'NazKlase')]\ndata.opFinal1 = data.opFinal[10270:17534,]\ndata.opFinal2 = data.opFinal[6870:10260,]\ndata.opFinal3 = data.opFinal[1:6860,]\ndata.opFinalPravi = rbind(data.opFinal1,data.opFinal2,data.opFinal3)\n\ndata.matrixOpBioclimFinal = data.matrixOpBioclim[c('Bio_1', 'Bio_2', 'Bio_3', 'Bio_4', 'Bio_5', 'Bio_6', 'Bio_7', 'Bio_8', 'Bio_9', 'Bio_10','Bio_11', 'Bio_12', 'Bio_13', 'Bio_14', 'Bio_15', 'Bio_16', 'Bio_17', 'Bio_18', 'Bio_19')]\ndata.matrixOpDemFinal = data.matrixOpDem[c('EKSPOZICIJ', 'NDM__M_', 'NAGIB_TERE')]\n\nresult.op = cbind(data.opFinalPravi, data.matrixOpBioclimFinal, data.matrixOpDemFinal)\n\n# Stvaranje spojene matrice za Lit ------------------------------------------------------------\n\ndata.litFinal = nalLit[c('OznKoord', 'NazKlase')]\n\ndata.matrixLitBioclimFinal = data.matrixLitBioclim[c('Bio_1', 'Bio_2', 'Bio_3', 'Bio_4', 'Bio_5', 'Bio_6', 'Bio_7', 'Bio_8', 'Bio_9', 'Bio_10','Bio_11', 'Bio_12', 'Bio_13', 'Bio_14', 'Bio_15', 'Bio_16', 'Bio_17', 'Bio_18', 'Bio_19')]\ndata.matrixLitDemFinal = data.matrixLitDem[c('EKSPOZICIJ', 'NDM__M_', 'NAGIB_TERE')]\n\nresult.lit = cbind(data.litFinal, data.matrixLitBioclimFinal, data.matrixLitDemFinal)\n\n\n# Stvaranje CSV rezultata za prikaz -----------------------------------------------------------\n\nwrite.csv2(result.op, \"resultOpazanje2.csv\", quote = F)\n\nwrite.csv2(result.lit, \"resultLiteratura2.csv\", quote = F)\n\n# Zajednicki CSV -----------------------------------------------------------------------------\nresult.final = rbind(result.op, result.lit)\n\nrows_to_keep = apply(result.final[c(3:24)], 1, function(row) !any(row == -9999))\nresult.final = result.final[rows_to_keep,]\n\nresult.final = na.omit(result.final)\n\nwrite.csv2(result.final, \"resultFinal2.csv\", quote = F)\n\n\n\n# Stvaranje podataka za pojedinu biljku ------------------------------------------------------\n\nrows_ambrosia = apply(result.final[c(1:24)], 1, function(row) any(row == \"Ambrosia artemisiifolia L.\"))\nrows_fagus = apply(result.final[c(1:24)], 1, function(row) any(row == \"Fagus sylvatica L.\"))\nrows_carpinus = apply(result.final[c(1:24)], 1, function(row) any(row == \"Carpinus betulus L.\"))\nrows_quercus = apply(result.final[c(1:24)], 1, function(row) any(row == \"Quercus petraea (Mattuschka) Liebl.\"))\nrows_fraxinus = apply(result.final[c(1:24)], 1, function(row) any(row == \"Fraxinus ornus L.\"))\n\nambrosia = result.final[rows_ambrosia,]\nfagus = result.final[rows_fagus,]\ncarpinus = result.final[rows_carpinus,]\nquercus = result.final[rows_quercus,]\nfraxinus = result.final[rows_fraxinus,]\n\n\n\n# Create final AMBROSIA data\n\nambrosia_zeros = fagus[sample(1:nrow(fagus), 500, replace = FALSE),]\ny = rep(0, 500);\n\nambrosia_zeros = cbind(ambrosia_zeros, y)\n\ny = rep(1, nrow(ambrosia))\nambrosia2 = cbind(ambrosia, y)\n\nambrosia_full = rbind(ambrosia2, ambrosia_zeros)\n\nmaxAmb = apply(ambrosia_full[3:24], 2, max)\nmeanAmb = apply(ambrosia_full[3:24], 2, mean)\n\n#ambrosia_norm = cbind(scale(ambrosia_full[3:24]), ambrosia_full[25])\n#ambrosia_norm\nmeanMatrix = do.call(rbind, replicate(nrow(ambrosia_full), meanAmb, simplify=FALSE)) \nambrosia_full[3:24] - meanMatrix\nambrosia_norm = (ambrosia_full[3:24]) / rep(maxAmb, each = nrow(ambrosia_full))\nambrosia_norm = cbind(ambrosia_norm, ambrosia_full[25])\n# Create final CARPINUS data\n\ncarpinus_zeros = fagus[sample(1:nrow(fagus), 1000, replace = FALSE),]\ny = rep(0, 1000);\n\ncarpinus_zeros = cbind(carpinus_zeros, y)\n\ny = rep(1, nrow(carpinus))\ncarpinus2 = cbind(carpinus, y)\n\ncarpinus_full = rbind(carpinus2, carpinus_zeros)\n\nmaxCar = apply(carpinus_full[3:24], 2, max)\nmeanCar = apply(carpinus_full[3:24], 2, mean)\n\nmeanMatrixC = do.call(rbind, replicate(nrow(carpinus_full), meanCar, simplify=FALSE)) \n\ncarp_norm = (carpinus_full[3:24]) / rep(maxCar, each = nrow(carpinus_full))\ncarp_norm = cbind(carp_norm, carpinus_full[25])\n\n\n# Create final FRAXINUS data\n\nfraxinus_zeros = fagus[sample(1:nrow(fagus), 1000, replace = FALSE),]\ny = rep(0, 1000);\n\nfraxinus_zeros = cbind(fraxinus_zeros, y)\n\ny = rep(1, nrow(fraxinus))\nfraxinus2 = cbind(fraxinus, y)\n\nfraxinus_full = rbind(fraxinus2, fraxinus_zeros)\n\nmaxFrx = apply(fraxinus_full[3:24], 2, max)\nmeanFrx = apply(fraxinus_full[3:24], 2, mean)\n\nmeanMatrixFx = do.call(rbind, replicate(nrow(fraxinus_full), meanFrx, simplify=FALSE)) \n\nfrax_norm = (fraxinus_full[3:24]) / rep(maxFrx, each = nrow(fraxinus_full))\nfrax_norm = cbind(frax_norm, fraxinus_full[25])\n\n\n\n# Create final FAGUS data\n\nfagus_zeros = fraxinus[sample(1:nrow(fraxinus), 1500, replace = FALSE),]\ny = rep(0, 1500);\n\nfagus_zeros = cbind(fagus_zeros, y)\n\ny = rep(1, nrow(fagus))\nfagus2 = cbind(fagus, y)\n\nfagus_full = rbind(fagus2, fagus_zeros)\n\nmaxFag = apply(fagus_full[3:24], 2, max)\nmeanFag = apply(fagus_full[3:24], 2, mean)\n\nmeanMatrixFg = do.call(rbind, replicate(nrow(fagus_full), meanFag, simplify=FALSE)) \n\nfag_norm = (fagus_full[3:24]) / rep(maxFag, each = nrow(fagus_full))\nfag_norm = cbind(fag_norm, fagus_full[25])\n\n\n\n# Create final quercus data\n\nquercus_zeros = fagus[sample(1:nrow(fagus), 1000, replace = FALSE),]\ny = rep(0, 1000);\n\nquercus_zeros = cbind(quercus_zeros, y)\n\ny = rep(1, nrow(quercus))\nquercus2 = cbind(quercus, y)\n\nquercus_full = rbind(quercus2, quercus_zeros)\n\nmaxQue = apply(quercus_full[3:24], 2, max)\nmeanQue = apply(quercus_full[3:24], 2, mean)\n\nmeanMatrixFx = do.call(rbind, replicate(nrow(quercus_full), meanQue, simplify=FALSE)) \n\nque_norm = (quercus_full[3:24]) / rep(maxQue, each = nrow(quercus_full))\nque_norm = cbind(que_norm, quercus_full[25])\n\n# Logistic Regression constants\n\nalpha <- .1\n\ngradient <- function(X, y, theta, alpha, iterations){\n  m = nrow(X)\n  length(X * theta )\n  for(i in 1:iterations){\n    temp = (t(X %*% theta - y) %*% X / m)\n    theta = theta - alpha * t(temp)\n  }\n  \n  return(theta)\n}\n\n# Train AMBROSIA\n\nsmp_size = floor(0.75 * nrow(ambrosia_norm))\n\nset.seed(123)\ntrain_indices = sample(seq_len(nrow(ambrosia_norm)), size = smp_size)\n\ntrain.ambrosia = ambrosia_norm[train_indices,]\ntest.ambrosia = ambrosia_norm[-train_indices,]\n\ny_amb = data.matrix(train.ambrosia[c(\"y\")])\nX_amb = data.matrix(train.ambrosia[, -which(names(train.ambrosia) %in% c(\"y\"))])\n\ntheta_amb_initial <- matrix(rep(0, ncol(X_amb)), nrow = ncol(X_amb), ncol = 1)\n\n#theta = gradient(X_amb, y_amb, theta_amb_initial, alpha, 1500)\n\nm = nrow(X_amb)\n\nfor(i in 1:5000){\n  temp = (t(X_amb %*% theta_amb_initial - y_amb) %*% X_amb / m)\n  theta_amb_initial = theta_amb_initial - alpha * t(temp)\n}\n\nX_amb_test = data.matrix(test.ambrosia[, -which(names(test.ambrosia) %in% c(\"y\"))])\n\nresults_amb = 1 / (1 + exp(-1 * X_amb_test %*% theta_amb_initial))\nresults_amb\n\ntemp = rep(0, nrow(results_amb))\nfor(j in 1:nrow(results_amb)){\n  if(results_amb[j] > 0.63){\n    temp[j] = 1\n  }\n}\ntemp\n\nresults_y_amb = test.ambrosia[, which(names(test.ambrosia) %in% c(\"y\"))]\nresults_y_amb\n\ntemp == y_amb\n\n#install.packages('e1071')\nlibrary(e1071)\nX_amb\nsvm.model <- svm(y_amb ~ . , data = X_amb, cost = 100, gamma = 0.1, scale = TRUE, type=\"C-classification\")\npred <- predict(svm.model, X_amb_test)\n\npred\n\n\n\n## ANN\n\n#install.packages('neuralnet')\n#library(\"neuralnet\")\n\n#ann.model <- neuralnet(y_amb~Bio_1+Bio_2+Bio_3+Bio_4+Bio_5+Bio_6+Bio_7+Bio_8+Bio_9+Bio_10+Bio_11+Bio_12+Bio_13+Bio_14+Bio_15+Bio_16+Bio_17+Bio_18+Bio_19+EKSPOZICIJ+NDM__M_+NAGIB_TERE,X_amb, hidden=2, threshold=0.01)\n\n#ann.result <- compute(ann.model, X_amb_test)\n#str(ann.result$neurons)\n\n#ann.pred <- prediction(ann.model, list.glm = NULL)\n\n#install.packages('nnet')\nlibrary(nnet)\n\nseedsANN = nnet(y_amb~., X_amb, size=23, rang = 0.5, maxit = 100)\n\npredict(seedsANN, X_amb_test, type=\"raw\")\n\n\n\n### MAXENT\n\ninstall.packages('maxent')\nlibrary(maxent)\n\nmxent.model <- maxent(X_amb, y_amb)\nmaxent.result <- predict.maxent(mxent.model, X_amb_test)\nmaxent.result\n\n\n\n#### DECISION TREES\n\ninstall.packages('party')\nlibrary(party)\n\ndataTree = as.factor(cbind(y_amb_df,X_amb))\nTreeModel = ctree('y~Bio_1+Bio_2+Bio_3+Bio_4+Bio_5+Bio_6+Bio_7+Bio_8+Bio_9+Bio_10+Bio_11+Bio_12+Bio_13+Bio_14+Bio_15+Bio_16+Bio_17+Bio_18+Bio_19+EKSPOZICIJ+NDM__M_+NAGIB_TERE', dataTree)\n\n\n\n\n\n\n# Train CAR\n\nsmp_size = floor(0.75 * nrow(carp_norm))\n\nset.seed(123)\ntrain_indices = sample(seq_len(nrow(carp_norm)), size = smp_size)\n\ntrain.carp = carp_norm[train_indices,]\ntest.carp = carp_norm[-train_indices,]\n\ny_car = data.matrix(train.carp[c(\"y\")])\nX_car = data.matrix(train.carp[, -which(names(train.carp) %in% c(\"y\"))])\n\ntheta_car_initial <- matrix(rep(0, ncol(X_car)), nrow = ncol(X_car), ncol = 1)\n\n#theta = gradient(X_amb, y_amb, theta_amb_initial, alpha, 1500)\n\nmc = nrow(X_car)\n\nfor(i in 1:5000){\n  temp = (t(X_car %*% theta_car_initial - y_car) %*% X_car / mc)\n  theta_car_initial = theta_car_initial - alpha * t(temp)\n}\n\nX_car_test = data.matrix(test.carp[, -which(names(test.carp) %in% c(\"y\"))])\n\nresults_car = 1 / (1 + exp(-1 * X_car_test %*% theta_car_initial))\nresults_car\nnrow(results_car)\ntemp = rep(0, nrow(results_car))\nfor(j in 1:nrow(results_car)){\n  if(results_car[j] > 0.63){\n    temp[j] = 1\n  }\n}\ntemp\n\nresults_y_car = test.carp[, which(names(test.carp) %in% c(\"y\"))]\nresults_y_car\n\nsum(temp == results_y_car)\n\n#install.packages('e1071')\nlibrary(e1071)\nX_car\nsvm.modelC <- svm(y_car ~ . , data = X_car, cost = 100, gamma = 0.1, scale = TRUE, type=\"C-classification\")\npredC <- predict(svm.modelC, X_car_test)\n\npredC\n\n\n\n## ANN\n\n#install.packages('neuralnet')\n#library(\"neuralnet\")\n\n#ann.model <- neuralnet(y_amb~Bio_1+Bio_2+Bio_3+Bio_4+Bio_5+Bio_6+Bio_7+Bio_8+Bio_9+Bio_10+Bio_11+Bio_12+Bio_13+Bio_14+Bio_15+Bio_16+Bio_17+Bio_18+Bio_19+EKSPOZICIJ+NDM__M_+NAGIB_TERE,X_amb, hidden=2, threshold=0.01)\n\n#ann.result <- compute(ann.model, X_amb_test)\n#str(ann.result$neurons)\n\n#ann.pred <- prediction(ann.model, list.glm = NULL)\n\n#install.packages('nnet')\nlibrary(nnet)\n\nseedsANNC = nnet(y_car~., X_car, size=23, rang = 5, maxit = 1000)\n\njok = round(predict(seedsANNC, X_car_test, type=\"raw\"))\nsum(jok == results_y_car)\n\n### MAXENT\n\ninstall.packages('maxent')\nlibrary(maxent)\n\nmxent.modelC <- maxent(X_car, y_car)\nmaxent.resultC <- predict.maxent(mxent.modelC, X_car_test)\nmaxent.resultC\nsum(maxent.resultC == results_y_car)\n\n\n\n\n\n\n\n# Train FRX\n\nsmp_size = floor(0.75 * nrow(frax_norm))\n\nset.seed(123)\ntrain_indices = sample(seq_len(nrow(frax_norm)), size = smp_size)\n\ntrain.frax = frax_norm[train_indices,]\ntest.frax = frax_norm[-train_indices,]\n\ny_frx = data.matrix(train.frax[c(\"y\")])\nX_frx = data.matrix(train.frax[, -which(names(train.frax) %in% c(\"y\"))])\n\ntheta_frx_initial <- matrix(rep(0, ncol(X_frx)), nrow = ncol(X_frx), ncol = 1)\n\n#theta = gradient(X_amb, y_amb, theta_amb_initial, alpha, 1500)\n\nmc = nrow(X_frx)\n\nfor(i in 1:5000){\n  temp = (t(X_frx %*% theta_frx_initial - y_frx) %*% X_frx / mc)\n  theta_frx_initial = theta_frx_initial - alpha * t(temp)\n}\n\nX_frx_test = data.matrix(test.frax[, -which(names(test.frax) %in% c(\"y\"))])\n\nresults_frx = 1 / (1 + exp(-1 * X_frx_test %*% theta_frx_initial))\nresults_frx\nnrow(results_frx)\ntemp = rep(0, nrow(results_frx))\nfor(j in 1:nrow(results_frx)){\n  if(results_frx[j] > 0.63){\n    temp[j] = 1\n  }\n}\ntemp\n\nresults_y_frx = test.frax[, which(names(test.frax) %in% c(\"y\"))]\nresults_y_frx\n\nsum(temp == results_y_frx)\n\n#install.packages('e1071')\nlibrary(e1071)\nX_frx\nsvm.modelFx <- svm(y_frx ~ . , data = X_frx, cost = 1000, gamma = 0.01, scale = TRUE, type=\"C-classification\")\npredC <- predict(svm.modelC, X_frx_test)\n\nsum(predC == results_y_frx)\n\n\n\n## ANN\n\n#install.packages('neuralnet')\n#library(\"neuralnet\")\n\n#ann.model <- neuralnet(y_amb~Bio_1+Bio_2+Bio_3+Bio_4+Bio_5+Bio_6+Bio_7+Bio_8+Bio_9+Bio_10+Bio_11+Bio_12+Bio_13+Bio_14+Bio_15+Bio_16+Bio_17+Bio_18+Bio_19+EKSPOZICIJ+NDM__M_+NAGIB_TERE,X_amb, hidden=2, threshold=0.01)\n\n#ann.result <- compute(ann.model, X_amb_test)\n#str(ann.result$neurons)\n\n#ann.pred <- prediction(ann.model, list.glm = NULL)\n\n#install.packages('nnet')\nlibrary(nnet)\n\nseedsANNC = nnet(y_frx~., X_frx, size=23, rang = 5, maxit = 1000)\n\njok = round(predict(seedsANNC, X_frx_test, type=\"raw\"))\nsum(jok == results_y_frx)\n\n### MAXENT\n\ninstall.packages('maxent')\nlibrary(maxent)\n\nmxent.modelC <- maxent(X_frx, y_frx)\nmaxent.resultC <- predict.maxent(mxent.modelC, X_frx_test)\nmaxent.resultC\nsum(maxent.resultC == results_y_frx)\n\n\n\n\n\n\n\n# Train FRX\n\nsmp_size = floor(0.75 * nrow(fag_norm))\n\nset.seed(123)\ntrain_indices = sample(seq_len(nrow(fag_norm)), size = smp_size)\n\ntrain.fag = fag_norm[train_indices,]\ntest.fag = fag_norm[-train_indices,]\n\ny_fag = data.matrix(train.fag[c(\"y\")])\nX_fag = data.matrix(train.fag[, -which(names(train.fag) %in% c(\"y\"))])\n\ntheta_fag_initial <- matrix(rep(0, ncol(X_fag)), nrow = ncol(X_fag), ncol = 1)\n\n#theta = gradient(X_amb, y_amb, theta_amb_initial, alpha, 1500)\n\nmc = nrow(X_fag)\n\nfor(i in 1:5000){\n  temp = (t(X_fag %*% theta_fag_initial - y_fag) %*% X_fag / mc)\n  theta_fag_initial = theta_fag_initial - alpha * t(temp)\n}\n\nX_fag_test = data.matrix(test.fag[, -which(names(test.fag) %in% c(\"y\"))])\n\nresults_fag = 1 / (1 + exp(-1 * X_fag_test %*% theta_fag_initial))\nresults_fag\nnrow(results_fag)\ntemp = rep(0, nrow(results_fag))\nfor(j in 1:nrow(results_fag)){\n  if(results_fag[j] > 0.63){\n    temp[j] = 1\n  }\n}\ntemp\n\nresults_y_fag = test.fag[, which(names(test.fag) %in% c(\"y\"))]\nresults_y_fag\n\nsum(temp == results_y_fag)\n\n#install.packages('e1071')\nlibrary(e1071)\nX_fag\nsvm.modelFg <- svm(y_fag ~ . , data = X_fag, cost = 100, gamma = 0.1, scale = TRUE, type=\"C-classification\")\npredC <- predict(svm.modelFg, X_fag_test)\n\nsum(predC == results_y_fag)\n\n\n\n## ANN\n\n#install.packages('neuralnet')\n#library(\"neuralnet\")\n\n#ann.model <- neuralnet(y_amb~Bio_1+Bio_2+Bio_3+Bio_4+Bio_5+Bio_6+Bio_7+Bio_8+Bio_9+Bio_10+Bio_11+Bio_12+Bio_13+Bio_14+Bio_15+Bio_16+Bio_17+Bio_18+Bio_19+EKSPOZICIJ+NDM__M_+NAGIB_TERE,X_amb, hidden=2, threshold=0.01)\n\n#ann.result <- compute(ann.model, X_amb_test)\n#str(ann.result$neurons)\n\n#ann.pred <- prediction(ann.model, list.glm = NULL)\n\n#install.packages('nnet')\nlibrary(nnet)\n\nseedsANNC = nnet(y_fag~., X_fag, size=23, rang = 5, maxit = 1000)\n\njok = round(predict(seedsANNC, X_fag_test, type=\"raw\"))\nsum(jok == results_y_fag)\n\n### MAXENT\n\ninstall.packages('maxent')\nlibrary(maxent)\n\nmxent.modelC <- maxent(X_fag, y_fag)\nmaxent.resultC <- predict.maxent(mxent.modelC, X_fag_test)\nmaxent.resultC\nsum(maxent.resultC == results_y_fag)\n\n\n\n\n\n\n\n# Train FRX\n\nsmp_size = floor(0.75 * nrow(que_norm))\n\nset.seed(123)\ntrain_indices = sample(seq_len(nrow(que_norm)), size = smp_size)\n\ntrain.q = que_norm[train_indices,]\ntest.q = que_norm[-train_indices,]\n\ny_q = data.matrix(train.q[c(\"y\")])\nX_q = data.matrix(train.q[, -which(names(train.q) %in% c(\"y\"))])\n\ntheta_q_initial <- matrix(rep(0, ncol(X_q)), nrow = ncol(X_q), ncol = 1)\n\n#theta = gradient(X_amb, y_amb, theta_amb_initial, alpha, 1500)\n\nmc = nrow(X_q)\n\nfor(i in 1:5000){\n  temp = (t(X_q %*% theta_q_initial - y_q) %*% X_q / mc)\n  theta_q_initial = theta_q_initial - alpha * t(temp)\n}\n\nX_q_test = data.matrix(test.q[, -which(names(test.q) %in% c(\"y\"))])\n\nresults_q = 1 / (1 + exp(-1 * X_q_test %*% theta_q_initial))\nresults_q\nnrow(results_q)\ntemp = rep(0, nrow(results_q))\nfor(j in 1:nrow(results_q)){\n  if(results_q[j] > 0.63){\n    temp[j] = 1\n  }\n}\ntemp\n\nresults_y_q = test.q[, which(names(test.q) %in% c(\"y\"))]\nresults_y_q\n\nsum(temp == results_y_q)\n\n#install.packages('e1071')\nlibrary(e1071)\nX_q\nsvm.modelq <- svm(y_q ~ . , data = X_q, cost = 100, gamma = 0.1, scale = TRUE, type=\"C-classification\")\npredC <- predict(svm.modelq, X_q_test)\n\nsum(predC == results_y_q)\n\n\n\n## ANN\n\n#install.packages('neuralnet')\n#library(\"neuralnet\")\n\n#ann.model <- neuralnet(y_amb~Bio_1+Bio_2+Bio_3+Bio_4+Bio_5+Bio_6+Bio_7+Bio_8+Bio_9+Bio_10+Bio_11+Bio_12+Bio_13+Bio_14+Bio_15+Bio_16+Bio_17+Bio_18+Bio_19+EKSPOZICIJ+NDM__M_+NAGIB_TERE,X_amb, hidden=2, threshold=0.01)\n\n#ann.result <- compute(ann.model, X_amb_test)\n#str(ann.result$neurons)\n\n#ann.pred <- prediction(ann.model, list.glm = NULL)\n\n#install.packages('nnet')\nlibrary(nnet)\n\nseedsANNC = nnet(y_q~., X_q, size=23, rang = 5, maxit = 1000)\n\njok = round(predict(seedsANNC, X_q_test, type=\"raw\"))\nsum(jok == results_y_q)\n\n### MAXENT\n\ninstall.packages('maxent')\nlibrary(maxent)\n\nmxent.modelC <- maxent(X_q, y_q)\nmaxent.resultC <- predict.maxent(mxent.modelC, X_q_test)\nmaxent.resultC\nsum(maxent.resultC == results_y_q)\n",
    "created" : 1452455532964.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1825228248",
    "id" : "C533C75D",
    "lastKnownWriteTime" : 1453650938,
    "path" : "C:/Users/Valentino/Desktop/FER/Završni/Projekt diplomski/ProjektDiplomski/spojiPoKoordinatama.R",
    "project_path" : "spojiPoKoordinatama.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_source"
}